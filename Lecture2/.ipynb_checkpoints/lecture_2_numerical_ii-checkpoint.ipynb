{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Week 2: Numerical Basics: Part II \n",
    "## Data Science Fundamentals \n",
    "## Representation of numbers \n",
    "\n",
    "------\n",
    " ##### DSF - University of Glasgow - Chris McCaig - 2021/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary <a class=\"tocSkip\">\n",
    "By the end of this unit you should know:\n",
    "    \n",
    "## Arithmetic, broadcasting and aggregation\n",
    "* scalar and elementwise arithmetic on arrays\n",
    "* broadcasting rules\n",
    "* basic aggregation operations like summation, mean, cumulative sum\n",
    "* sorting and selection like argmax, argsort, find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary <a class=\"tocSkip\">\n",
    "By the end of this unit you should know:\n",
    "\n",
    "## Floating point numbers\n",
    "* how IEEE 754 `float32` and `float64` numbers are represented\n",
    "* how infinity and NaN are represented, how they occur and how they are used\n",
    "* what roundoff error is and how it tends to be caused\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:35:04.078627Z",
     "start_time": "2020-09-27T12:35:04.067890Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "IPython.display.HTML(\n",
    "    \"\"\"\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:17:37.127111Z",
     "start_time": "2020-09-27T13:17:35.686670Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -U --no-cache https://github.com/johnhw/jhwutils/zipball/master\n",
    "from jhwutils.float_inspector import print_shape_html, print_float, print_float_html\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jhwutils.matrices import show_boxed_tensor_latex, print_matrix\n",
    "import jhwutils.image_audio as ia\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc(\"figure\", figsize=(7, 3.5), dpi=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Map: arithmetic on arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The major advantage of array representations is to be able to do arithmetic on arrays directly. \n",
    "\n",
    "Basic arithmetic is computed **elementwise**. This means that a function is applied to each element of an array. There are a few different kind of element wise operations:\n",
    "\n",
    "* single argument, like `np.tan()` or unary negative `(-x)`\n",
    "* two argument, like `x+y` or `x-1` or `np.maximum(x,y)`\n",
    "* and various other cases, like np.where(condition, true_values, false_values)`\n",
    "\n",
    "All of these work on arrays without any special syntax. We can simply write expressions using array variables.\n",
    "\n",
    "    x + y + 2  # if x and y are arrays, this just works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array([0, 1, 2, 3])\n",
    "print_matrix(\"x\", x)\n",
    "print_matrix(\"y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_matrix(\"x+y\", x+y)\n",
    "print_matrix(\"x-y\", x-y)\n",
    "print_matrix(\"x*y\", x*y)\n",
    "print_matrix(\"x/y\", x/y)\n",
    "print_matrix(\"x^y\", x**y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# examples with scalars and arrays\n",
    "print_matrix(\"x+1\", x + 1)\n",
    "print_matrix(\"2x\", x * 2)\n",
    "print_matrix(\"1/x\", 1 / x)\n",
    "print_matrix(\"x^2\", x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying simple functions\n",
    "Standard functions, like `cos` or `tan` can be applied to arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)\n",
    "plt.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An example: changing volume\n",
    "If a sound is just an array of values, then we can use array operations to apply changes to a whole sound at once.\n",
    "\n",
    "For example, scaling (multiplying the values) will change the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "guitar = ia.load_sound(\"sounds/guitar.wav\")\n",
    "ia.play_sound(guitar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ia.play_sound(guitar*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ia.play_sound(np.tanh(guitar*1200)*0.15) # distortion pedal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ia.play_sound(np.convolve(guitar, np.ones(50)/50)) # bass only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ia.play_sound(np.convolve(guitar, np.random.normal(0,1, 15000) * np.exp(-np.linspace(0, 5, 15000))) * 0.02) # reverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we wanted to fade out the sound, we'd need to multiply *each element* by a different value (e.g. fading from 0.0 to 1.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fade = np.linspace(1,0, len(guitar))**2\n",
    "ia.play_sound(guitar*fade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mixing sounds\n",
    "Mixing sounds simply involves adding them (and possibly reducing the gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sax = ia.load_sound(\"sounds/erhu.wav\")\n",
    "ia.play_sound(sax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = min(len(guitar), len(sax))\n",
    "# nb: here I slice so that both are the length of the shortest sound\n",
    "ia.play_sound(sax[:max_len] + guitar[:max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ia.play_sound(guitar[:max_len]*fade[:max_len]+\n",
    "           sax[:max_len]*(1-fade[:max_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Map\n",
    "This is a special case of a **map**: the application of a function to each element of a sequence.\n",
    "\n",
    "    \n",
    "There are certain rules which dictate what operations can be applied together.\n",
    "\n",
    "* For single argument operations, there is no problem; the operation is applied to each element of the array\n",
    "* If there are more than two arguments, like in `x + y`, then `x` and `y` must have **compatible shapes**. This means it must be possible to pair each element of `x` with a corresponding element of `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Same shape\n",
    "In the simplest case, `x` and `y` have the same shape; then the operation is applied to each pair of elements from `x` and `y` in sequence.\n",
    "\n",
    "### Not the same shape\n",
    "If `x` and `y` aren't the same shape, it might seem like they cannot be added (or divided, or \"maximumed\"). However, NumPy provides **broadcasting rules** to allow arrays to be automatically expanded to allow operations between certain shapes of arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Repeat until they match\n",
    "The rule is simple; if the arrays don't match in size, but one array can be *tiled* to be the same size as the other, this tiling is done implicitly as the operation occurs. For example, adding a scalar to an array implicitly *tiles* the scalar to the size of the array, then adds the two arrays together (this is done much more efficiently internally than explicitly generating the array).\n",
    "\n",
    "The easiest broadcasting rule is scalar arithmetic: `x+1` is valid for any array `x`, because NumPy **broadcasts** the 1 to make it the same shape as `x` and then adds them together, so that every element of `x` is paired with a 1.\n",
    "\n",
    "Broadcasting always works for any scalar and any array, because a scalar can be repeated however many times necessary to make the operation work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can imagine that `x+1` is really `x + np.tile(1, x.shape)` which works the same, but is much less efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.zeros((5, 5))\n",
    "x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# same, but creates large temporary array\n",
    "x + np.tile(1, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Broadcasting\n",
    "So far we have seen:\n",
    "* **elementwise array arithmetic** (both sides of an operator have exactly the same shape) and \n",
    "* **scalar arithmetic** (one side of the operator is a scalar, and the other is an array). \n",
    "\n",
    "This is part of a general pattern, which lets us very compactly write operations between arrays of different sizes, under some specific restrictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Broadcasting** is the way in which arithmetic operations are done on arrays when the operands are of different shapes.\n",
    "\n",
    "1. If the operands have the same number of dimensions, then they **must** have the same shape; operations are done elementwise. `y = x + x`\n",
    "1. If one operand is an array with fewer dimensions than the other, then if the *last dimensions* of the first array match the shape as the second array, operations are well-defined. If we have a LHS of size (...,j,k,l) and a RHS of (l) or (k,l) or (j,k,l) etc., then everything is OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This says for example that:\n",
    "\n",
    "    shape (2,2) * shape(2,) -> valid\n",
    "    shape (2,3,4) * shape(3,4) -> valid\n",
    "    shape (2,3,4) * shape(4,) -> valid\n",
    "    \n",
    "    shape (2,3,4) * shape (2,4) -> invalid \n",
    "    shape (2,3,4) * shape(2) --> invalid\n",
    "    shape (2,3,4) * shape(8) --> invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Broadcasting is just automatic tiling\n",
    "When broadcasting, the array is *repeated* or tiling as needed to expand to the correct size, then the operation is applied. So adding a (2,3) array and a (3,) array means repeating the (3,) array into 2 identical rows, then adding to the (2,3) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vec4 = np.array([1, 2, 3, 4])\n",
    "mat4 = np.zeros((4, 4))  # 4x4 zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mat3x4 = np.full((3, 4), 8.0)  # 3x4 filled with 8\n",
    "vec3 = np.array([1, 2, 3])\n",
    "vec4x = np.array([1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print((vec4+1))        # scalar (Rule 2)\n",
    "print((vec4 + vec4x))  # elementwise (Rule 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print((mat4 + mat4))   # elementwise (Rule 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# note that vec4 is repeated over the rows to make it the same size \n",
    "print((mat4 + vec4))   # broadcasting: valid because RHS (vec4) has dimension matching the last dimension of matt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# note that the operation operates across *columns*, i.e the last dimension of the array\n",
    "print((mat3x4 + vec4)) # broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# broadcasting also works on comparisons\n",
    "mat4x = np.array([[1,2,3,4],\n",
    "                  [4,5,6,7],\n",
    "                  [8,9,10,11],\n",
    "                  [12,13,14,15]])\n",
    "print((mat4x>vec4))\n",
    "# note this has compared [1,2,3,4] to each row of mat4x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Invalid broadcasting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print((mat3x4 + vec3)) # invalid: last dimensions don't match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print((mat4+vec3)) # invalid: last dimensions don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print((mat4+mat3x4)) # invalid: arrays have same rank but different shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transposing in broadcasts\n",
    "Transpose solves one of the problems you might have seen with broadcasting. Imagine we want to add a vector to every row of a matrix. This is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.zeros((4,3)) # 4 rows, 3 columns\n",
    "y = np.array([1,1,9]) # 3 element vector, applies to each row\n",
    "print_matrix(\"x\",x )\n",
    "print_matrix(\"y\",y)\n",
    "# this will repeat the 3 element vector into 4 rows, then add\n",
    "print_matrix(\"x+y\",x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But how would we add a vector to each *column*? This would need a 4 element vector, and this cannot be added directly as it violates the broadcasting rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z = np.array([1,2,3,4])\n",
    "print_matrix(\"x+z\", x+z) # this can't work; a 4x3 and a 4 don't have matching last dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But the **transpose** of `x` is a 3x4 matrix, to which `z` can be added. The result is transposed, so we transpose it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print_matrix(\"(x^T+z^T)^T\", (x.T + z).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduction\n",
    "\n",
    "**Reduction** (sometimes called **fold**) is the process of applying an operator or function with two arguments repeatedly to\n",
    "some sequence. \n",
    "\n",
    "For example, if we reduce [1,2,3,4] with `+`, the result is `1+2+3+4 = 10`. If we reduce `[1,2,3,4]` with `*`, the result is `1*2*3*4 = 24`. \n",
    "\n",
    "**Reduction: stick an operator in between elements**\n",
    "\n",
    "    1 2 3 4\n",
    "    5 6 7 8\n",
    "   \n",
    "Reduce on columns with \"+\":\n",
    "\n",
    "    1 + 2 + 3 + 4  =  10\n",
    "    5 + 6 + 7 + 8  =  26\n",
    "    \n",
    "Reduce on rows with \"+\":\n",
    "\n",
    "    1 2 3 4\n",
    "    + + + +\n",
    "    5 6 7 8\n",
    "    \n",
    "    = \n",
    "    6 8 10 12\n",
    "    \n",
    "Reduce on rows then columns:\n",
    "\n",
    "    1 + 2 + 3 + 4\n",
    "    +   +   +   +\n",
    "    5 + 6 + 7 + 8\n",
    "    \n",
    "    = \n",
    "    6 + 8 + 10 + 12  = 36\n",
    "\n",
    "\n",
    "Many operations can be expressed as reductions. These are **aggregate** operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`np.any` and `np.all` test if an array of Boolean values is all True or not all False (i.e. if any element is True). These are one kind of **aggregate function** -- a function that processes an array and returns a single value which \"summarises\" the array in some way.\n",
    "\n",
    "* `np.any` is the reduction with logical OR\n",
    "* `np.all` is the reduction with logical AND\n",
    "* `np.min` is the reduction with min(a,b)\n",
    "* `np.max` is the reduction with max(a,b)\n",
    "* `np.sum` is the reduction with +\n",
    "* `np.prod` is the reduction with *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"any\", np.any([True, False, False]))  # true = True or False or False\n",
    "print(\"all\", np.all([True, False, False]))  # false = True and False and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6])  # 1 + 2 + 3 + 4 + 5 + 6\n",
    "print(np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.prod(x))  # 1 * 2 * 3 * 4 * 5 * 6 = 6!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(x))  # max(max(max(max(max(1,2), 3), 4), 5), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some functions are built on top of reductions:\n",
    "* `np.mean` is the sum divided by the number of elements reduced\n",
    "* `np.std` computes the standard deviation using the mean, then some elementwise arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(x))\n",
    "print(np.sum(x) / len(x))  # equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By default, aggregate functions operate over the whole array, regardless of how many dimensions it has. This means reducing over the last axis, then reducing over the second last axis, and so on, until a single scalar remains. For example, `np.max(x)`, if `x` is a 2D array, will compute the reduction across columns and get the max for each row, then reduce over rows to get the max over the whole array.\n",
    "\n",
    "We can specify the specific axes to reduce on using the `axes=` argument to any function that reduces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print_matrix(\"x\", x)\n",
    "print(\"max(x)=\", np.max(x))  # reduce on all axes\n",
    "print_matrix(\"max_{0}(x)\", np.max(x, axis=0))  # reduce on rows\n",
    "print_matrix(\"max_{1}(x)\", np.max(x, axis=1))  # reduce on columns\n",
    "print_matrix(\"max_{0,1}(x)\",\n",
    "             np.max(x, axis=(0, 1)))  # same as all axes in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_matrix(\"\\\\text{mean}_0(x)\", np.mean(x, axis=0))  # mean on rows\n",
    "print_matrix(\"\\\\text{mean}_1(x)\", np.mean(x, axis=1))  # mean on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accumulation\n",
    "The sum of an array is a single scalar value. The **cumulative sum** or **running sum** of an array is an array of the same size, which stores the result of summing up every element until that point. \n",
    "\n",
    "This is almost the same as reduction, but we keep intermediate values during the computation, instead of collapsing to just the final result. The general process is called **accumulation** and it can be used with different operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, the accumulation of `[1,2,3,4]` with `+` is `[1, 1+2, 1+2+3, 1+2+3+4] = [1,3,6,10]`.\n",
    "\n",
    "* `np.cumsum` is the accumulation of `+`\n",
    "* `np.cumprod` is the accumulation of `*`\n",
    "* `np.diff` is the accumulation of `-` (but note that it has one less output than input)\n",
    "\n",
    "Accumulations operate on a single axis at a time, and you should specify this if you are using them on an array with more than one dimension (otherwise you will get the accumulation of flattened array). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_matrix(\"x\", x)\n",
    "print_matrix(\"\\\\text{cumsum}_0(x)\", \n",
    "             np.cumsum(x, axis=0)) # sum across rows\n",
    "print_matrix(\"\\\\text{cumprod}_1(x)\", \n",
    "             np.cumprod(x, axis=1)) # product across columns\n",
    "print_matrix(\"\\\\text{diff}_0(x)\", \n",
    "             np.diff(x, axis=0)) # difference across rows\n",
    "print_matrix(\"\\\\text{diff}_1(x)\", np.diff(x, axis=1)) # difference across columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `np.gradient` is like `np.diff` but uses central differences to get same length output, and it computes the gradient over *every* axis and returns them all in a list. It is a very useful function in image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_matrix(\"\\\\nabla x_0\", np.gradient(x)[0])\n",
    "print_matrix(\"\\\\nabla x_1\", np.gradient(x)[1])\n",
    "z = np.array([1,3,8,10,18])\n",
    "print_matrix(\"gradient(z**2)\",np.gradient(z**2))\n",
    "print_matrix(\"gradient(z**2)\",z**2)\n",
    "print_matrix(\"diff(z**2)\",np.diff(z**2))\n",
    "np.gradient(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding\n",
    "\n",
    "There are functions which find **indices** that satisfy criteria. For example, the largest value along some axis.\n",
    "\n",
    "* `np.argmax()` finds the index of the largest element\n",
    "* `np.argmin()` finds the index of the smallest element\n",
    "* `np.argsort()` finds the indices that would sort the array back into order\n",
    "* `np.nonzero()` finds indices that are non-zero (or True, for Boolean arrays)\n",
    "\n",
    "Finding indices is of great importance, because it allows us to cross-reference across axes or arrays. For example, we can find the row where some value is maximised (most wheat production) and then find the attribute which corresponds to it (the year when most wheat was produced).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([5,9,0,13,-8,7,2,8,0,-8])\n",
    "print_matrix(\"x\", x)\n",
    "# note: argmin/max will tie break on the first occurence\n",
    "print_matrix(\"argmin(x)\", np.argmin(x)) \n",
    "print_matrix(\"argmax(x)\", np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"nonzero(x)=\", np.nonzero(x))\n",
    "\n",
    "## argmin is almost the same as this\n",
    "## but this can return *multiple* minimums, instead of the first\n",
    "print(np.nonzero(x==np.min(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Argsorting\n",
    "**argsort** finds the indices that would put an array in order. It is an *extremely* useful operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices that would put x into order\n",
    "print_matrix('x', x)\n",
    "print_matrix('\\\\text{argsort}(x)', np.argsort(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hey presto! sorted!\n",
    "print_matrix('x[\\\\text{argsort}(x)]', x[np.argsort(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part II: Floating point\n",
    "\n",
    "What we are going to do: **understand how floating point ndarrays work, right down to the bits in memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algebra: a loss of structure\n",
    "The **algebraic properties** of operators on real numbers (associativity, distributivity, and commutativity) are *not* preserved with the representation of numbers that we use for computations. The approximations used to store these numbers efficiently for computational purposes means that:\n",
    "\n",
    "$$ab \\neq ba, a+b \\neq b+a, \\text{etc.}$$\n",
    "$$a(b+c) \\neq ab + bc$$\n",
    "$$a(bc) \\neq (ab)c$$\n",
    "\n",
    "Of course, most of the time, a good representation will be very close to these properties and they will almost hold, or at least hold for many specific examples. *But they are not preserved in general.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:48:38.170876Z",
     "start_time": "2020-09-27T12:48:38.167442Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(1e120 + 1e-120 + -1e120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:48:50.307402Z",
     "start_time": "2020-09-27T12:48:50.303495Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(1e120 + -1e120 + 1e-120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Number types\n",
    "There are different representations for numbers that can be stored in arrays. Of these, **integers** and **floating point numbers** are of most relevance. Integers are familiar in their operation, but floats have some subtlety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Integers\n",
    "Integers represent whole numbers (no fractional part). They come in two varieties: signed and unsigned. In memory, these are (normally!) stored as binary 2's complement (for signed) or unsigned binary (for unsigned).\n",
    "\n",
    "Most 64 bit systems support operations on at least the following integer types:\n",
    "\n",
    "| name   | bytes | min                        | max                        |\n",
    "|--------|-------|----------------------------|----------------------------|\n",
    "| int8   | 1     | -128                       | 127                        |\n",
    "| uint8  | 1     | 0                          | 255                        |\n",
    "| int16  | 2     | -32,768                    | 32,767                     |\n",
    "| uint16 | 2     | 0                          | 65,535                     |\n",
    "| int32  | 4     | -2,147,483,648             | 2,147,483,647              |\n",
    "| uint32 | 4     | 0                          | 4,294,967,295              |\n",
    "| int64  | 8     | -9,223,372,036,854,775,808 | +9,223,372,036,854,775,807 |\n",
    "| uint64 | 8     | 0                          | 18,446,744,073,709,551,615 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An operation which exceeds the bounds of the type results in **overflow**. Overflows have behaviour that may be undefined; for example adding 8 to the int8 value 120 (exceeds 127; result might be 127, or -128, or some other number). In most systems you will ever see, the result will be to wrap around, computing the operation modulo the range of the integer type.\n",
    "\n",
    "NumPy allows integer arrays, although we won't use them extensively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:50:37.275408Z",
     "start_time": "2020-09-27T12:50:37.269552Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "int_array = np.array([100, 110, 120], dtype=np.int8)\n",
    "\n",
    "print(int_array)\n",
    "print(int_array + 20)  # beware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:51:04.730515Z",
     "start_time": "2020-09-27T12:51:04.725635Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "uint_array = np.array([100, 110, 120], dtype=np.uint8)\n",
    "print(uint_array)\n",
    "\n",
    "print(uint_array + 20)  # ok\n",
    "print(uint_array + 150)  # wrap, but through 0 this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Floats\n",
    "\n",
    "<img src=\"imgs/floats.jpg\" width=\"80%\"> <br><br>\n",
    "\n",
    "*-[The other kind of floats](https://flickr.com/photos/59489479@N08/14526937582 \"glass floats\") by [siaronj](https://flickr.com/people/59489479@N08) shared [CC BY](https://creativecommons.org/licenses/by/2.0/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Floating point representation\n",
    "Integers have (very) limited range, and don't represent fractional parts of numbers. Floating point is the most common representation for numbers that may be very large or small, and where fractional parts are required. Most modern computing hardware supports floating point numbers directly in hardware.\n",
    "\n",
    "(side note: floating point isn't **required** for fractional representation; *fixed point* notation can also be used, but is much less flexible in terms of available range. It is often faster on simple hardware like microcontrollers; however modern CPUs and GPUs have extremely fast floating point units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/die-labeled.jpg\" width=\"25%\"> \n",
    "\n",
    "*The die of the 8087, the first Intel hardware floating point unit. From http://www.righto.com/2018/09/two-bits-per-transistor-high-density.html*\n",
    "\n",
    "Unlike integers, floating point numbers have some surprising properties which can cause **numerical issues**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A number in [1.0, 2.0) and a shift\n",
    "**All floating point numbers are is a compact way to represent numbers of very large range, by allowing a fractional number with a standardised range (*mantissa*, varies from 1.0 to just less than 2.0) with a scaling or stretching factor (*exponent*, varies in steps of powers of 2).**\n",
    "\n",
    "<img src=\"imgs/floats.svg\" width=\"100%\">\n",
    "\n",
    "*Floating point numbers can be thought of as numbers between 1.0 and 2.0, that can be shifted and stretched by doubling or halving repeatedly*\n",
    "\n",
    "\n",
    "\n",
    "The advantage of this is that the for a relatively small number of digits, a very large range of numbers can be represented. The precision, however, is variable, with very precise representation of small numbers (close to zero) and coarser representation of numbers far from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sign, exponent, mantissa\n",
    "\n",
    "A floating point number is represented by three parts, each of which is in practice an integer. Just like scientific notation, the number is separated into an exponent (the magnitude of a number) and a mantissa (the fractional part of a number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Scientific notation**\n",
    "\n",
    "For example, in scientific notation, `5340.2` is writen `5.3402 * 10^3` (or `5.3402e3`). Likewise, `0.00051` is written `5.1 * 10^(-4)` or `5.1e-4`. There is always *exactly* one digit before the decimal point; the \"shift\" to put the decimal in the right place is written in the exponent portion.\n",
    "\n",
    "       5.3402     * 10 ^ 3\n",
    "       [mantissa] * 10 ^ [exponent]\n",
    "\n",
    "The advantage of this is that for a relatively small number of digits, a very large range of numbers can be represented. The precision, however, is variable, with very precise representation of small numbers (close to zero) and coarser representation of numbers far from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Binary floating point\n",
    "In binary floating point, calculations are done base 2, and every number is split into three parts. These parts are:\n",
    "\n",
    "* the **sign**; a single bit indicating if a number is positive or negative\n",
    "* the **exponent**; a signed integer indicating how much to \"shift\" the mantissa by\n",
    "* the **mantissa**; an unsigned integer representing the fractional part of the number, following the 1.\n",
    "\n",
    "A floating point number is equal to:\n",
    "\n",
    "    sign * (1.[mantissa]) * (2^exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The leading one    \n",
    "Note that a leading 1 is inserted before the mantissa; this is because it is unnecessary to represent the first digit, as we know the mantissa represents a number between 1.0 (inclusive) and 2.0 (exclusive). Instead, the leading one is *implicitly* present in all computations.\n",
    "\n",
    "The mantissa is always a positive number, stored as an integer such that it would be shifted until the first digit was just after the decimal point. So a mantissa which was stored as a 23 digit binary integer $00100111010001001000101_2$ would really represent the number $1.00100111010001001000101_2$\n",
    "The exponent is stored as a positive integer, with an implied \"offset\" to allow it to represent negative numbers. \n",
    "\n",
    "For example, in `float32`, the format is:\n",
    "\n",
    "    1     8      23\n",
    "    sign  exp.   mantisssa\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The exponents in `float32` are stored with an implied offset of -127 (the \"bias\"), so exponent=0 really means exponent=-127.\n",
    "\n",
    "So if we had a `float32` number\n",
    "\n",
    "      1 10000011 00100111010001001000101\n",
    "      \n",
    "What do we know? \n",
    "\n",
    "1. The number is negative, because leading bit (sign bit) is 1.\n",
    "1. The mantissa represents $1.00100111010001001000101_2 = 1.153389573097229_{10}$\n",
    "1. The exponent represents $2^{131-127} = 2^4 = 16$ ($1000011_2=131_{10}$), because of the implied offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the number which is represented can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T12:59:25.070425Z",
     "start_time": "2020-09-27T12:59:25.064568Z"
    }
   },
   "outputs": [],
   "source": [
    "sign = \"1\"\n",
    "exponent = \"10000011\"\n",
    "mantissa = \"00100111010001001000101\"\n",
    "\n",
    "exponent = int(exponent, 2) - 127  # compensate for bias\n",
    "mantissa = 1.0 + int(mantissa, 2) / 2 ** len(mantissa)  # convert to 1.xxxx format\n",
    "\n",
    "print(\"exponent (decimal, including bias)\", exponent)\n",
    "print(\"mantissa (decimal, including leading 1)\", mantissa)\n",
    "\n",
    "if sign == \"1\":\n",
    "    number = -1 * mantissa * 2 ** exponent\n",
    "else:\n",
    "    number = mantissa * 2 ** exponent\n",
    "\n",
    "print(\"number\", number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### IEEE 754\n",
    "The dominant standard for floating point numbers is IEEE754, which specifies both a representation for floating point numbers and operations defined upon them, along with a set of conventions for \"special\" numbers.\n",
    "\n",
    "The IEEE754 standard types are given below:\n",
    "\n",
    "| Name       | Common name         | Base | Digits | Decimal digits | Exponent bits | Decimal E max | Exponent bias  | E min   | E max   | Notes     |\n",
    "|------------|---------------------|------|--------|----------------|---------------|---------------|----------------|---------|---------|-----------|\n",
    "| binary16   | Half precision      | 2    | 11     | 3.31           | 5             | 4.51          | 2^4−1 = 15      | −14     | +15     | not basic |\n",
    "| **binary32**   | Single precision    | 2    | 24     | 7.22           | 8             | 38.23         | 2^7−1 = 127     | −126    | +127    |           |\n",
    "| **binary64**   | Double precision    | 2    | 53     | 15.95          | 11            | 307.95        | 2^10−1 = 1023   | −1022   | +1023   |           |\n",
    "| binary128  | Quadruple precision | 2    | 113    | 34.02          | 15            | 4931.77       | 2^14−1 = 16383  | −16382  | +16383  |           |\n",
    "| binary256  | Octuple precision   | 2    | 237    | 71.34          | 19            | 78913.2       | 2^18−1 = 262143 | −262142 | +262143 | not basic |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Floats, doubles \n",
    "Almost all floating point computations are either done in **single precision** (**float32**, sometimes just called \"float\") or **double precision** (**float64**, sometimes just called \"double\"). \n",
    "\n",
    "##### float32\n",
    "**float32** is 32 bits, or 4 bytes per number; **float64** is 64 bits or 8 bytes per number.\n",
    "\n",
    "GPUs typically are fastest (by a long way) using **float32**, but can do double precision **float64** computations at some significant cost. \n",
    "\n",
    "#### float64\n",
    "**float64** is 64 bits, or 8 bytes per number. Most desktop CPUs (e.g. x86) have specialised **float64** hardware (or for x86 slightly odd 80-bit \"long double\" representations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exotic floating point numbers\n",
    "Some GPUs can do very fast **float16** operations, but this is an unusual format outside of some specialised machine learning applications, where precision isn't critical. (there is even various kinds of **float8** used occasionally).\n",
    "\n",
    "**float128** and **float256** are very rare outside of astronomical simulations where tiny errors matter and scales are very large. For example, [JPL's ephemeris of the solar system](https://ssd.jpl.nasa.gov/?ephemerides) is computed using `float128`. Software support for `float128` or `float256` is relatively rare. NumPy does not support `float128` or `float256`, for example (it seems like it does, but it doesn't).\n",
    "\n",
    "IEEE 754 also specifies **floating-point decimal** formats that are rarely used outside of specialised applications, like some calculators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary representation of floats\n",
    "We can take any float and look at its representation in memory, where it will be a fixed length sequence of bits (e.g. float64 = 64 bits). This can be split up into the sign, exponent and mantissa. Let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:02:16.104263Z",
     "start_time": "2020-09-27T13:02:16.099382Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:02:57.562357Z",
     "start_time": "2020-09-27T13:02:57.558453Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:03:19.427317Z",
     "start_time": "2020-09-27T13:03:19.422437Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:03:40.855834Z",
     "start_time": "2020-09-27T13:03:40.851929Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:03:59.658572Z",
     "start_time": "2020-09-27T13:03:59.654163Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(1.0 / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:04:29.356492Z",
     "start_time": "2020-09-27T13:04:29.351611Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(2000000.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:05:08.988676Z",
     "start_time": "2020-09-27T13:05:08.984266Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(6.02e23)  # Avogadro's number (approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:05:42.295119Z",
     "start_time": "2020-09-27T13:05:42.290239Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(1e-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:06:16.060296Z",
     "start_time": "2020-09-27T13:06:16.056393Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(1.5e300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Integers in floats\n",
    "For **float64**, every integer from $-2^{53}$ to $2^{53}$ is precisely representable; integers outside of this range are not represented exactly (this is because the mantissa is effectively 53 bits, including the implicit leading 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:07:14.065670Z",
     "start_time": "2020-09-27T13:07:14.063201Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Float\\t\", 1.0 * 2 ** 53 - 1)\n",
    "\n",
    "print(\"Integer\\t\", 2 ** 53 - 1)  # exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:07:27.917756Z",
     "start_time": "2020-09-27T13:07:27.914323Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Float\\t\", 1.0 * 2 ** 53 + 1)\n",
    "print(\"Integer\\t\", 2 ** 53 + 1)  # not the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:07:44.620392Z",
     "start_time": "2020-09-27T13:07:44.616487Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Float\\t {1.0 * 7 ** 33 + 1:.8f}\")\n",
    "print(\"Integer\\t\", 7 ** 33 + 1)  # very different!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special features of floats\n",
    "As well as their huge range, floats have some special properties that are critical for numerical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Float exceptions\n",
    "Float operations, unlike integers, can cause *exceptions* to happen during calculations. These exceptions occur at the *hardware* level, not in the operating system or language. The OS/language can configure how to respond to them (for example, Unix systems send the signal SIGFPE to the process which can handle it how it wishes).\n",
    "\n",
    "There are five standard floating point exceptions that can occur.\n",
    "\n",
    "* **Invalid Operation**\n",
    "Occurs when an operation without a defined real number result is attempted, like 0.0 / 0.0 or sqrt(-1.0).\n",
    "\n",
    "*  **Division by Zero**\n",
    "Occurs when dividing by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Overflow**\n",
    "Occurs if the result of a computation exceeds the limits of the floating point number (e.g. a `float64` operations results in a number > 1e308)\n",
    "\n",
    "* **Underflow**\n",
    "Occurs if the result of a computation is smaller than the smallest representable number, and so is rounded off to zero.\n",
    "\n",
    "* **Inexact**\n",
    "Occurs if a computation will produce an inexact result due to rounding.\n",
    "\n",
    "----\n",
    "\n",
    "Each exception can be **trapped** or **untrapped**. An untrapped exception will not halt execution, and will instead do some default operation (e.g. untrapped divide by zero will output infinity instead of halting). A trapped exception will cause the process to be signaled in to indicate that the operation is problematic, at which point it can either halt or take another action.\n",
    "\n",
    "Usually, `invalid operation` is trapped, and `inexact` and `underflow` are not trapped. `overflow` and `division by zero` may or may not be trapped. NumPy traps all except `inexact`, but normally just prints a warning and continues; it can be configured to halt and raise an exception instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:15:26.028235Z",
     "start_time": "2020-09-27T13:15:25.138886Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.array(0.0) / np.array(0.0)  # invalid operation (results in nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:15:33.579683Z",
     "start_time": "2020-09-27T13:15:32.706938Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(1.0) / np.array(0.0)  # divide by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:15:38.641107Z",
     "start_time": "2020-09-27T13:15:37.768251Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(2.0) / np.array(3.0)  # inexact (not trapped by NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:15:49.569294Z",
     "start_time": "2020-09-27T13:15:48.694112Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(100.0) * np.array(1e307)  # overflow (results in inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:17:23.258223Z",
     "start_time": "2020-09-27T13:17:23.248Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.array(0.000001) * np.array(\n",
    "    1e-307\n",
    ")  # underflow (results in smallest possible float, by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:16:16.452834Z",
     "start_time": "2020-09-27T13:16:16.312760Z"
    }
   },
   "outputs": [],
   "source": [
    "np.seterr(under=\"raise\")  # enable underflow trap\n",
    "np.array(000000.1) * np.array(\n",
    "    1e-307\n",
    ")  # underflow (results in smallest possible float, by default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special numbers: zero, inf and NaN\n",
    "### Zero: +0.0 and -0.0\n",
    "\n",
    "IEEE 754 has both positive and negative zero representations. Positive zero has zero sign, exponent and mantissa. Negative zero has the sign bit set.\n",
    "\n",
    "Positive and negative 0.0 compare equal, and work exactly the same in all operations, except for the sign bit propagating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:17:45.132010Z",
     "start_time": "2020-09-27T13:17:45.127139Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(+0.0)  # this is an all zero bit pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:05.206892Z",
     "start_time": "2020-09-27T13:18:05.202011Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(-0.0)  # this has the sign bit set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:14.279590Z",
     "start_time": "2020-09-27T13:18:14.275685Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "0.0 == -0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:16.553075Z",
     "start_time": "2020-09-27T13:18:16.549171Z"
    }
   },
   "outputs": [],
   "source": [
    "-0.0 < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:27.313247Z",
     "start_time": "2020-09-27T13:18:26.431782Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "2 * -0.0  # sign bit propagates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:30.077955Z",
     "start_time": "2020-09-27T13:18:29.192502Z"
    }
   },
   "outputs": [],
   "source": [
    "0.0 * 2  # sign bit propagates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:34.745759Z",
     "start_time": "2020-09-27T13:18:33.869680Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "-0.0 ** 2 # sign propagates (even here!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Infinity: +∞ and -∞\n",
    "\n",
    "IEEE 754 floating point numbers **explicitly** encode infinities. They do this using a bit pattern of all ones for the exponent, and all zeros for the mantissa. The sign bit indicates whether the number is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:18:58.827448Z",
     "start_time": "2020-09-27T13:18:58.823544Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# np.inf is a constant equal to infinity\n",
    "print_float_html(np.inf)  # positive infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:14.659313Z",
     "start_time": "2020-09-27T13:19:14.654433Z"
    }
   },
   "outputs": [],
   "source": [
    "print_float_html(-np.inf)  # negative infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:30.154153Z",
     "start_time": "2020-09-27T13:19:29.288267Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.inf + 1  # infinity + anything = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:38.489031Z",
     "start_time": "2020-09-27T13:19:37.617278Z"
    }
   },
   "outputs": [],
   "source": [
    "np.inf * 2  # same with other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:41.078816Z",
     "start_time": "2020-09-27T13:19:40.215424Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.inf * 0  # but infinity * 0  is undefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:54.068739Z",
     "start_time": "2020-09-27T13:19:53.205386Z"
    }
   },
   "outputs": [],
   "source": [
    "np.inf - np.inf # not 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:19:59.979597Z",
     "start_time": "2020-09-27T13:19:59.103482Z"
    }
   },
   "outputs": [],
   "source": [
    "np.inf / np.inf  # as is infinity / infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:20:04.516602Z",
     "start_time": "2020-09-27T13:20:03.641450Z"
    }
   },
   "outputs": [],
   "source": [
    "-0.0 * np.inf  # infinity has a sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NaN: 👵🏻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN or **Not A Number** is a particularly important special \"number\". NaN is used to represent values that are invalid; for example, the result of 0.0 / 0.0. All of the following result in NaN:\n",
    "* `0 / 0`\n",
    "* `inf / inf` (either positive or negative inf)\n",
    "* `inf - inf` or `inf + -inf`\n",
    "* `inf * 0` or  `0 * -inf`\n",
    "* `sqrt(x)`, if x<0\n",
    "* `log(x)`, if x<0\n",
    "* Any other operation that would have performed any of these calculations internally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NaN has several properties:\n",
    "\n",
    "* it **propagates**: any floating point operation involving NaN has the output NaN. (almost: `1.0**nan==1.0`).\n",
    "* any comparison with NaN evaluates to false. NaN is not equal to anything, **including itself**; nor is it greater than or lesser than any other number. It is the only floating point number not equal to itself.\n",
    "* NaN, however, is *not* equivalent to False in Python\n",
    "\n",
    "It is both used as the *output of operations* (to indicate where something has gone wrong), and deliberately as a *placeholder in arrays* (e.g. to signal missing data in a dataset). \n",
    "\n",
    "NaN has all ones exponent, but non-zero mantissa. Note that this means there is *not* a unique bit pattern for NaN. There are $2^{52}-1$ different NaNs in `float64` for example, all of which behave the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:22:17.814815Z",
     "start_time": "2020-09-27T13:22:17.810000Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# np.nan is a constant equal to nan\n",
    "print_float_html(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:22:38.529255Z",
     "start_time": "2020-09-27T13:22:38.525352Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(np.nan * 5)  # nan propagates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:22:40.539191Z",
     "start_time": "2020-09-27T13:22:40.535288Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sin(np.nan))  # every operation involving nan evaluates to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:22:43.315909Z",
     "start_time": "2020-09-27T13:22:43.312005Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.nan > 5)  # comparisons are always false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:22:46.806804Z",
     "start_time": "2020-09-27T13:22:46.802901Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.nan == np.nan)  # comparisons are always false, even equality to itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:23:00.546751Z",
     "start_time": "2020-09-27T13:23:00.542847Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if np.nan:\n",
    "    print(\"NaN is truthy\")\n",
    "else:\n",
    "    print(\"NaN is falsey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.isnan(a)` tests if an array has `nan` in it (and is exactly the same as `a!=a`, because of NaN's comparison property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:23:22.886277Z",
     "start_time": "2020-09-27T13:23:22.881398Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "num = np.array([1, 0, 1])\n",
    "den = np.array([1, 0, 0])\n",
    "\n",
    "quot = num / den\n",
    "print(quot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:23:35.656697Z",
     "start_time": "2020-09-27T13:23:35.652793Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.isnan(quot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:23:44.032822Z",
     "start_time": "2020-09-27T13:23:44.028920Z"
    }
   },
   "outputs": [],
   "source": [
    "print(quot != quot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### NaN as a result\n",
    "It is very common experience to write some numerical code, and discover that the result is just NaN. This is because NaN propagates -- once it \"infects\" some numerical process, it will spread to all future calculations. This makes sense, since NaN indicates that no useful operation can be done. However, it can be a frustrating experience to debug NaN sources. \n",
    "\n",
    "The most common cause is **underflow** rounding a number to 0 or **overflow** rounding a number to +/-`inf`, which then gets used in one of the \"blacklisted\" operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:25:19.900525Z",
     "start_time": "2020-09-27T13:25:19.893693Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.normal(1, 0.4, 100)\n",
    "print(np.cumsum(x * np.log(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### NaN as a mask\n",
    "Sometimes NaN is used to mask parts of arrays that have missing data. While there is specialised support for masked arrays in some languages/packages, NaNs are available everywhere and don't require any special storage or data structures.\n",
    "\n",
    "For example, plotting data with NaN's in it results in gaps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T13:26:11.472295Z",
     "start_time": "2020-09-27T13:26:11.296577Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "year = [1978, 1979, 1980, 1981, 1982, 1983, 1984]\n",
    "price = [5.0, 4.9, 5.2, np.nan, np.nan, 8.9, 9.25]  # no data for 1981 or 1982\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(year, price, \"-o\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources for this lecture\n",
    "* **From Python to Numpy** http://www.labri.fr/perso/nrougier/from-python-to-numpy/ *recommended reading*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
